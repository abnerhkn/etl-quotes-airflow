# ğŸ“ Projeto ETL de Web Scraping de Frases

Este projeto implementa um pipeline **ETL (Extract, Transform, Load)** usando **Apache Airflow** para coletar frases do site [Quotes to Scrape](https://quotes.toscrape.com/), armazenÃ¡-las em um banco de dados **PostgreSQL** e exibi-las em um **dashboard interativo com Streamlit**.

## ğŸ“Œ Arquitetura

![Arquitetura do Projeto](etl_quotes_architecture.png)

1. **Extract** â†’ O Airflow executa um script Python (`extract_quotes.py`) que faz scraping das frases e salva em `quotes.csv`.
2. **Transform** â†’ (Opcional neste projeto) Limpeza e padronizaÃ§Ã£o dos dados.
3. **Load** â†’ O Airflow executa um script (`load_quotes.py`) que insere os dados no PostgreSQL.
4. **VisualizaÃ§Ã£o** â†’ O Streamlit consome os dados do banco e exibe no dashboard.

---

## ğŸš€ Tecnologias Utilizadas
- **Python 3.10**
- **Apache Airflow 2.8.1**
- **PostgreSQL**
- **Streamlit**
- **Docker & Docker Compose**
- **BeautifulSoup4**
- **Pandas**
- **Requests**

---

## ğŸ“‚ Estrutura de Pastas

```
.
â”œâ”€â”€ dags/                      # DAGs do Airflow
â”‚   â”œâ”€â”€ etl_quotes.py           # DAG principal do ETL
â”‚   â””â”€â”€ ...
â”œâ”€â”€ scripts/                   # Scripts Python usados no ETL
â”‚   â”œâ”€â”€ extract_quotes.py
â”‚   â”œâ”€â”€ load_quotes.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ streamlit-app/             # AplicaÃ§Ã£o Streamlit
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ plugins/                   # Plugins do Airflow (opcional)
â”œâ”€â”€ logs/                      # Logs do Airflow
â”œâ”€â”€ docker-compose.yml         # ConfiguraÃ§Ã£o dos containers
â”œâ”€â”€ requirements.txt           # DependÃªncias extras (opcional)
â””â”€â”€ README.md                  # DocumentaÃ§Ã£o do projeto
```

---

## âš™ï¸ Como Executar o Projeto

### 1ï¸âƒ£ PrÃ©-requisitos
- **Docker** e **Docker Compose** instalados.
- Porta `8080` (Airflow), `5433` (PostgreSQL) e `8501` (Streamlit) livres.

### 2ï¸âƒ£ Subir os serviÃ§os
```bash
docker compose up -d
```

Isso iniciarÃ¡:
- **PostgreSQL** (`localhost:5433`)
- **Airflow Webserver** (`http://localhost:8080`)
- **Streamlit App** (`http://localhost:8501`)

### 3ï¸âƒ£ Acessar o Airflow
1. Entre no Airflow em `http://localhost:8080`
2. UsuÃ¡rio padrÃ£o: `airflow` / Senha: `airflow` (ou o que vocÃª definiu)
3. Ative a DAG `etl_quotes` e execute manualmente ou aguarde a execuÃ§Ã£o diÃ¡ria.

### 4ï¸âƒ£ Visualizar no Streamlit
ApÃ³s o ETL carregar os dados no banco, acesse:
```
http://localhost:8501
```
O dashboard exibirÃ¡ as frases e autores coletados.

---

## ğŸ“Š Fluxo do ETL

1. **Extract**: `extract_quotes.py` â†’ Faz scraping das pÃ¡ginas do site e salva `quotes.csv`.
2. **Transform**: (Opcional) â†’ Limpeza e formataÃ§Ã£o de dados.
3. **Load**: `load_quotes.py` â†’ LÃª `quotes.csv` e insere no PostgreSQL.
4. **VisualizaÃ§Ã£o**: `app.py` (Streamlit) â†’ Consulta no PostgreSQL e exibe dados.

---

## ğŸ“Œ PossÃ­veis Melhorias
- Implementar camada **Transform** para limpeza de dados.
- Criar testes automatizados.
- Usar **dbt** para modelagem e transformaÃ§Ã£o no banco.
- Adicionar grÃ¡ficos no Streamlit.

---

## ğŸ“œ LicenÃ§a
Este projeto Ã© de uso livre para estudos e fins acadÃªmicos.

---